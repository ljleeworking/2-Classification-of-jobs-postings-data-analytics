{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Job Postings (Data Analytics)\n",
    "\n",
    "## Business Case Overview\n",
    "\n",
    "You're working as a data scientist for a contracting firm that's rapidly expanding. Now that they have their most valuable employee (you!), they need to leverage data to win more contracts. Your firm offers technology and scientific solutions and wants to be competitive in the hiring market. Your principal has two main objectives:\n",
    "\n",
    "   1. Determine the industry factors that are most important in predicting the salary amounts for these data.\n",
    "   2. Determine the factors that distinguish job categories and titles from each other. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### QUESTION 1: Factors that impact salary\n",
    "\n",
    "To predict salary you can frame this as a classification problem, in which case you will create labels from these salaries (high vs. low salary, for example) according to thresholds (such as median salary).\n",
    "\n",
    "\n",
    "### QUESTION 2: Factors that distinguish job category\n",
    "\n",
    "There are a variety of interesting ways you can frame the target variable, for example:\n",
    "- What components of a job posting distinguish data scientists from other data jobs?\n",
    "- What features are important for distinguishing junior vs. senior positions?\n",
    "- Do the requirements for titles vary significantly with industry ?\n",
    "\n",
    "###  Overview:\n",
    "\n",
    "Part 1. Scrape and prepare your own data.\n",
    "\n",
    "Part 2. Data Cleaning and Exploratory data analysis (EDA)\n",
    "\n",
    "Part 3. Modelling and evaluation\n",
    "\n",
    "Part 4. Executive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv file\n",
    "csv = './cleaned_df.csv'\n",
    "df = pd.read_csv(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Modelling and evaluation\n",
    "### Question 1 - Factors that impact salary. Set as a classification problem\n",
    "\n",
    "\n",
    "1a) First i took a look at columns 'company','job_title','location','employment_type','seniority','job_categories' individually in relation with salary. \n",
    "\n",
    "1b) Then i put the features from above all together and analysed. (for the boss who is interested in the overall features)\n",
    "\n",
    "1c) Look at columns 'job_description' and \t'requirements'. (for HR who is interested in which skills and Keywords)\n",
    "\n",
    "Models used: BernoulliNB, Logistic regression, Decision tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5750.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['high_pay'] = df.salary_avg\n",
    "df.salary_avg.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to binary classification\n",
    "df.loc[df.salary_avg <= 5750, 'high_pay'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.salary_avg> 5750, 'high_pay'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5    1.0\n",
       "6    1.0\n",
       "7    0.0\n",
       "8    1.0\n",
       "9    1.0\n",
       "Name: high_pay, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.high_pay.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2637, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>seniority</th>\n",
       "      <th>job_categories</th>\n",
       "      <th>job_description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>high_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>national university of singapore</td>\n",
       "      <td>senior / associate director, data governance /...</td>\n",
       "      <td>lower kent ridge road</td>\n",
       "      <td>permanent, full time</td>\n",
       "      <td>senior management</td>\n",
       "      <td>education and training, information technology</td>\n",
       "      <td>\\r\\r\\nthis leadership role will interact and e...</td>\n",
       "      <td>\\r\\r\\ndegree in information technology, comput...</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ntuc enterprise nexus co-operative limited</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>marina boulevard</td>\n",
       "      <td>full time</td>\n",
       "      <td>executive</td>\n",
       "      <td>information technology</td>\n",
       "      <td>\\r\\r\\nntuc enterprise is in the midst of its d...</td>\n",
       "      <td>\\r\\r\\n• masters in statistics, mathematics, co...</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     company  \\\n",
       "0           0            national university of singapore   \n",
       "1           1  ntuc enterprise nexus co-operative limited   \n",
       "\n",
       "                                           job_title                 location  \\\n",
       "0  senior / associate director, data governance /...   lower kent ridge road    \n",
       "1                                     data scientist        marina boulevard    \n",
       "\n",
       "        employment_type          seniority  \\\n",
       "0  permanent, full time  senior management   \n",
       "1             full time          executive   \n",
       "\n",
       "                                   job_categories  \\\n",
       "0  education and training, information technology   \n",
       "1                          information technology   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  \\r\\r\\nthis leadership role will interact and e...   \n",
       "1  \\r\\r\\nntuc enterprise is in the midst of its d...   \n",
       "\n",
       "                                        requirements  salary_low  salary_high  \\\n",
       "0  \\r\\r\\ndegree in information technology, comput...      7000.0       9000.0   \n",
       "1  \\r\\r\\n• masters in statistics, mathematics, co...      3500.0      10000.0   \n",
       "\n",
       "   salary_avg  high_pay  \n",
       "0      8000.0       1.0  \n",
       "1      6750.0       1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a) Features of 'company', 'job_title', 'location', 'employment_type', 'seniority', 'job_categories' that affect salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse at company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 salary_avg\n",
      "company                                                    \n",
      "cardinal health singapore 225 pte. ltd.        21500.000000\n",
      "mastercard asia/pacific pte. ltd.              21125.000000\n",
      "smith & nephew pte. limited                    21000.000000\n",
      "airbnb singapore private limited               20000.000000\n",
      "amazon web services singapore private limited  19261.904762\n",
      "                                   salary_avg\n",
      "company                                      \n",
      "smartkarma innovations pte. ltd.       1000.0\n",
      "ardex singapore pte. ltd.               900.0\n",
      "fyreflyz pte. ltd.                      700.0\n",
      "rht management services pte. ltd.       700.0\n",
      "four star industries pte ltd            650.0\n"
     ]
    }
   ],
   "source": [
    "group=df.groupby('company')[['salary_avg']].mean()\n",
    "company_pay=group.sort_values(by='salary_avg',ascending = False)\n",
    "\n",
    "print(company_pay.head(5))\n",
    "# companies with the highest average salary\n",
    "\n",
    "print(company_pay.tail(5))\n",
    "# companies with the worst average salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), max_features=100, binary=True, stop_words='english')\n",
    "title_words = cv.fit_transform(df.job_title)\n",
    "title_words = pd.DataFrame(title_words.todense(), columns=cv.get_feature_names())\n",
    "X_train, X_test, y_train, y_test = train_test_split(title_words.values, df.high_pay.values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75757576 0.71212121 0.75252525 0.77777778 0.69191919 0.72222222\n",
      " 0.72222222 0.73232323 0.75126904 0.80612245]\n",
      "0.7426078353199455\n",
      "0.4795144157814871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_scores = cross_val_score(BernoulliNB(), X_train, y_train, cv=10)\n",
    "print(nb_scores)\n",
    "print(np.mean(nb_scores))\n",
    "print(np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      high_p     low_p     feature  high_diff\n",
      "55  0.209474  0.094083     manager   0.115390\n",
      "80  0.204211  0.107662      senior   0.096548\n",
      "31  0.161053  0.064985        data   0.096067\n",
      "26  0.088421  0.031038  consultant   0.057383\n",
      "21  0.076842  0.032008    business   0.044834\n",
      "53  0.054737  0.011639        lead   0.043098\n",
      "37  0.067368  0.025218   developer   0.042150\n",
      "86  0.049474  0.010669   singapore   0.038804\n",
      "78  0.048421  0.009699   scientist   0.038722\n",
      "40  0.038947  0.001940    director   0.037008\n",
      "      high_p     low_p            feature  high_diff\n",
      "15  0.005263  0.029098  assistant manager  -0.023835\n",
      "84  0.004211  0.029098            service  -0.024887\n",
      "96  0.001053  0.028128         technician  -0.027075\n",
      "27  0.012632  0.039767           contract  -0.027136\n",
      "72  0.031579  0.066925           research  -0.035346\n",
      "1   0.001053  0.046557           accounts  -0.045504\n",
      "61  0.003158  0.049467            officer  -0.046309\n",
      "4   0.002105  0.056256              admin  -0.054151\n",
      "43  0.009474  0.139670          executive  -0.130197\n",
      "14  0.012632  0.145490          assistant  -0.132858\n",
      "0.7378787878787879\n",
      "0.5015151515151515\n"
     ]
    }
   ],
   "source": [
    "feat_lp = nb.feature_log_prob_\n",
    "high_p = np.exp(feat_lp[1])\n",
    "low_p = np.exp(feat_lp[0])\n",
    "# Make a dataframe with the probabilities and features\n",
    "feat_probs = pd.DataFrame({'high_p':high_p, 'low_p':low_p, 'feature':title_words.columns.values})\n",
    "#  Create a column that is the difference between high probability of appearance and low\n",
    "feat_probs['high_diff'] = feat_probs.high_p - feat_probs.low_p\n",
    "\n",
    "# Look at the most likely words for high and low salary\n",
    "feat_probs.sort_values('high_diff', ascending=False, inplace=True)  # most low, use ascending=True\n",
    "print(feat_probs.head(10))\n",
    "print(feat_probs.tail(10))\n",
    "\n",
    "# model on the test set\n",
    "print(nb.score(X_test, y_test))\n",
    "print(np.mean(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job title\n",
    "\n",
    "- Best paying features: manager,senior, consultant, business,developer,scientist,director\n",
    "\n",
    "- Worst paying features: executive, assistant, accounts, admin, officer, technician"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse at seniority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), max_features=20, binary=True, stop_words='english')\n",
    "seniority_words = cv.fit_transform(df.seniority)\n",
    "seniority_words = pd.DataFrame(seniority_words.todense(), columns=cv.get_feature_names())\n",
    "X_train, X_test, y_train, y_test = train_test_split(seniority_words.values, df.high_pay.values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72864322 0.7638191  0.73737374 0.78282828 0.68181818 0.70558376\n",
      " 0.7106599  0.74111675 0.70050761 0.69035533]\n",
      "0.7242705863831799\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_scores = cross_val_score(BernoulliNB(), X_train, y_train, cv=10)\n",
    "print(nb_scores)\n",
    "print(np.mean(nb_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      high_p     low_p            feature  high_diff\n",
      "16  0.333685  0.144101       professional   0.189585\n",
      "17  0.261880  0.122824             senior   0.139056\n",
      "10  0.166843  0.029981         management   0.136862\n",
      "11  0.194298  0.074468            manager   0.119830\n",
      "19  0.090813  0.009671  senior management   0.081142\n",
      "18  0.173178  0.114120   senior executive   0.059059\n",
      "12  0.080253  0.024178             middle   0.056075\n",
      "13  0.080253  0.024178  middle management   0.056075\n",
      "4   0.023231  0.031915   executive senior  -0.008684\n",
      "3   0.008448  0.039652   executive junior  -0.031204\n",
      "      high_p     low_p           feature  high_diff\n",
      "5   0.007392  0.135397             fresh  -0.128005\n",
      "6   0.007392  0.135397       fresh entry  -0.128005\n",
      "9   0.007392  0.135397             level  -0.128005\n",
      "1   0.007392  0.135397       entry level  -0.128005\n",
      "0   0.007392  0.135397             entry  -0.128005\n",
      "14  0.047518  0.177950               non  -0.130431\n",
      "15  0.047518  0.177950     non executive  -0.130431\n",
      "7   0.022175  0.184720            junior  -0.162544\n",
      "8   0.022175  0.184720  junior executive  -0.162544\n",
      "2   0.399155  0.728240         executive  -0.329085\n",
      "0.7287878787878788\n"
     ]
    }
   ],
   "source": [
    "feat_lp = nb.feature_log_prob_\n",
    "high_p = np.exp(feat_lp[1])\n",
    "low_p = np.exp(feat_lp[0])\n",
    "# Make a dataframe with the probabilities and features\n",
    "feat_probs = pd.DataFrame({'high_p':high_p, 'low_p':low_p, 'feature':seniority_words.columns.values})\n",
    "#  Create a column that is the difference between high probability of appearance and low\n",
    "feat_probs['high_diff'] = feat_probs.high_p - feat_probs.low_p\n",
    "\n",
    "# Look at the most likely words for high and low salary\n",
    "feat_probs.sort_values('high_diff', ascending=False, inplace=True)  # most low, use ascending=True\n",
    "print(feat_probs.head(10))\n",
    "print(feat_probs.tail(10))\n",
    "\n",
    "# model on the test set\n",
    "print(nb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seniority\n",
    "\n",
    "- Best paying features: professional, management, senior management, middle management\n",
    "\n",
    "- Worst paying features: executive, junior executive, non executive, entry level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse at job_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), max_features=30, binary=True, stop_words='english')\n",
    "job_categories_words = cv.fit_transform(df.job_categories)\n",
    "job_categories_words = pd.DataFrame(job_categories_words.todense(), columns=cv.get_feature_names())\n",
    "X_train, X_test, y_train, y_test = train_test_split(job_categories_words.values, df.high_pay.values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65326633 0.68686869 0.62626263 0.65656566 0.71212121 0.63131313\n",
      " 0.63451777 0.63959391 0.68527919 0.71573604]\n",
      "0.6641524548342905\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_scores = cross_val_score(BernoulliNB(), X_train, y_train, cv=10)\n",
    "print(nb_scores)\n",
    "print(np.mean(nb_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      high_p     low_p                 feature  high_diff\n",
      "29  0.489097  0.241650              technology   0.247446\n",
      "14  0.489097  0.241650  information technology   0.247446\n",
      "13  0.489097  0.241650             information   0.247446\n",
      "6   0.109034  0.052063                 banking   0.056971\n",
      "7   0.109034  0.052063         banking finance   0.056971\n",
      "10  0.109034  0.052063                 finance   0.056971\n",
      "8   0.066459  0.025540              consulting   0.040919\n",
      "22  0.043614  0.036346               relations   0.007268\n",
      "21  0.043614  0.036346        public relations   0.007268\n",
      "19  0.043614  0.036346        marketing public   0.007268\n",
      "      high_p     low_p              feature  high_diff\n",
      "17  0.020768  0.055992     logistics supply  -0.035224\n",
      "27  0.020768  0.055992         supply chain  -0.035224\n",
      "1   0.023884  0.122790  accounting auditing  -0.098906\n",
      "5   0.023884  0.122790    auditing taxation  -0.098906\n",
      "4   0.023884  0.122790             auditing  -0.098906\n",
      "28  0.023884  0.122790             taxation  -0.098906\n",
      "0   0.023884  0.122790           accounting  -0.098906\n",
      "3   0.004154  0.118861    admin secretarial  -0.114707\n",
      "2   0.004154  0.118861                admin  -0.114707\n",
      "26  0.004154  0.118861          secretarial  -0.114707\n",
      "0.6530303030303031\n"
     ]
    }
   ],
   "source": [
    "feat_lp = nb.feature_log_prob_\n",
    "high_p = np.exp(feat_lp[1])\n",
    "low_p = np.exp(feat_lp[0])\n",
    "# Make a dataframe with the probabilities and features\n",
    "feat_probs = pd.DataFrame({'high_p':high_p, 'low_p':low_p, 'feature':job_categories_words.columns.values})\n",
    "#  Create a column that is the difference between high probability of appearance and low\n",
    "feat_probs['high_diff'] = feat_probs.high_p - feat_probs.low_p\n",
    "\n",
    "# Look at the most likely words for high and low salary\n",
    "feat_probs.sort_values('high_diff', ascending=False, inplace=True)  # most low, use ascending=True\n",
    "print(feat_probs.head(10))\n",
    "print(feat_probs.tail(10))\n",
    "\n",
    "# model on the test set\n",
    "print(nb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job categories\n",
    "\n",
    "- Best paying features: information technology, consulting, banking finance\n",
    "\n",
    "- Worst paying features: admin secretarial, accounting, auditing taxation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse at location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), max_features=200, binary=True, stop_words=['boulevard','road','quay','way'])\n",
    "location_words = cv.fit_transform(df.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_words = pd.DataFrame(location_words.todense(), columns=cv.get_feature_names())\n",
    "X_train, X_test, y_train, y_test = train_test_split(location_words.values, df.high_pay.values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62311558 0.64646465 0.62121212 0.67171717 0.5959596  0.58080808\n",
      " 0.6751269  0.60913706 0.62944162 0.60913706]\n",
      "0.6262119833644971\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_scores = cross_val_score(BernoulliNB(), X_train, y_train, cv=10)\n",
    "print(nb_scores)\n",
    "print(np.mean(nb_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       high_p     low_p          feature  high_diff\n",
      "106  0.121901  0.030602           marina   0.091299\n",
      "155  0.065083  0.029615          shenton   0.035468\n",
      "144  0.050620  0.025666         robinson   0.024953\n",
      "33   0.035124  0.011846  changi business   0.023278\n",
      "23   0.047521  0.024679    business park   0.022841\n",
      "22   0.047521  0.024679         business   0.022841\n",
      "12   0.032025  0.011846          battery   0.020179\n",
      "32   0.042355  0.022705           changi   0.019651\n",
      "124  0.067149  0.048371             park   0.018778\n",
      "139  0.076446  0.058243          raffles   0.018203\n",
      "       high_p     low_p         feature  high_diff\n",
      "143  0.028926  0.050346           ridge  -0.021420\n",
      "87   0.028926  0.050346            kent  -0.021420\n",
      "88   0.028926  0.050346      kent ridge  -0.021420\n",
      "116  0.006198  0.030602  nanyang avenue  -0.024404\n",
      "115  0.006198  0.030602         nanyang  -0.024404\n",
      "117  0.032025  0.057256           north  -0.025231\n",
      "99   0.006198  0.034551           lebar  -0.028352\n",
      "132  0.006198  0.034551      paya lebar  -0.028352\n",
      "131  0.006198  0.034551            paya  -0.028352\n",
      "6    0.061983  0.103653          avenue  -0.041669\n",
      "0.6757575757575758\n"
     ]
    }
   ],
   "source": [
    "feat_lp = nb.feature_log_prob_\n",
    "high_p = np.exp(feat_lp[1])\n",
    "low_p = np.exp(feat_lp[0])\n",
    "# Make a dataframe with the probabilities and features\n",
    "feat_probs = pd.DataFrame({'high_p':high_p, 'low_p':low_p, 'feature':location_words.columns.values})\n",
    "#  Create a column that is the difference between high probability of appearance and low\n",
    "feat_probs['high_diff'] = feat_probs.high_p - feat_probs.low_p\n",
    "\n",
    "# Look at the most likely words for high and low salary\n",
    "feat_probs.sort_values('high_diff', ascending=False, inplace=True)  # most low, use ascending=True\n",
    "print(feat_probs.head(10))\n",
    "print(feat_probs.tail(10))\n",
    "# model on the test set\n",
    "print(nb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location\n",
    "\n",
    "- Best paying features: central busniess district - (marina, robinson, shenton, raffles) and business park\n",
    "\n",
    "- Worst paying features: universities  -(kent ridge, nanyang avenue) and paya lebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse at employment_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), max_features=40, binary=True, stop_words='english')\n",
    "employment_type_words = cv.fit_transform(df.employment_type)\n",
    "employment_type_words = pd.DataFrame(employment_type_words.todense(), columns=cv.get_feature_names())\n",
    "X_train, X_test, y_train, y_test = train_test_split(employment_type_words.values, df.high_pay.values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53030303 0.58585859 0.5        0.54040404 0.53030303 0.48989899\n",
      " 0.58080808 0.55837563 0.46192893 0.53299492]\n",
      "0.5310875249961544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_scores = cross_val_score(BernoulliNB(), X_train, y_train, cv=10)\n",
    "print(nb_scores)\n",
    "print(np.mean(nb_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      high_p     low_p               feature  high_diff\n",
      "9   0.451143  0.396467             permanent   0.054676\n",
      "12  0.186071  0.173700        permanent time   0.012371\n",
      "10  0.018711  0.015702    permanent contract   0.003009\n",
      "15  0.001040  0.000981  temporary internship   0.000058\n",
      "22  0.001040  0.000981        time temporary   0.000058\n",
      "25  0.001040  0.001963       work internship  -0.000923\n",
      "20  0.001040  0.001963       time internship  -0.000923\n",
      "18  0.001040  0.001963         time contract  -0.000923\n",
      "11  0.001040  0.001963   permanent temporary  -0.000923\n",
      "2   0.001040  0.001963   contract internship  -0.000923\n",
      "      high_p     low_p             feature  high_diff\n",
      "5   0.001040  0.005888          flexi work  -0.004849\n",
      "4   0.001040  0.005888               flexi  -0.004849\n",
      "24  0.001040  0.005888                work  -0.004849\n",
      "21  0.001040  0.006869      time permanent  -0.005830\n",
      "8   0.001040  0.012758          internship  -0.011718\n",
      "14  0.006237  0.018646  temporary contract  -0.012409\n",
      "0   0.198545  0.216879            contract  -0.018335\n",
      "13  0.008316  0.040236           temporary  -0.031920\n",
      "17  0.615385  0.654563                time  -0.039179\n",
      "3   0.063410  0.104024       contract time  -0.040614\n",
      "0.4984848484848485\n"
     ]
    }
   ],
   "source": [
    "feat_lp = nb.feature_log_prob_\n",
    "high_p = np.exp(feat_lp[1])\n",
    "low_p = np.exp(feat_lp[0])\n",
    "# Make a dataframe with the probabilities and features\n",
    "feat_probs = pd.DataFrame({'high_p':high_p, 'low_p':low_p, 'feature':employment_type_words.columns.values})\n",
    "#  Create a column that is the difference between high probability of appearance and low\n",
    "feat_probs['high_diff'] = feat_probs.high_p - feat_probs.low_p\n",
    "\n",
    "# Look at the most likely words for high and low salary\n",
    "feat_probs.sort_values('high_diff', ascending=False, inplace=True)  # most low, use ascending=True\n",
    "print(feat_probs.head(10))\n",
    "print(feat_probs.tail(10))\n",
    "# model on the test set\n",
    "print(nb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### employment type\n",
    "\n",
    "- Best paying features: permanent\n",
    "\n",
    "- Worst paying features: temporary, contract, internship, flexi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b) Putting the features together (except job description and requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2637, 376)\n",
      "Index(['account', 'accounts', 'accounts assistant', 'accounts executive',\n",
      "       'admin', 'admin assistant', 'administrative', 'administrator',\n",
      "       'advisory', 'analyst',\n",
      "       ...\n",
      "       'temporary time', 'time', 'time contract', 'time flexi',\n",
      "       'time internship', 'time permanent', 'time temporary', 'time time',\n",
      "       'work', 'work internship'],\n",
      "      dtype='object', length=376)\n"
     ]
    }
   ],
   "source": [
    "features = pd.concat([title_words, seniority_words,job_categories_words,location_words,employment_type_words], axis=1, sort=False)\n",
    "print(features.shape)\n",
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2637, 1060)\n"
     ]
    }
   ],
   "source": [
    "companies = df['company']\n",
    "# convert dummy dummy-coded variables\n",
    "companies = pd.get_dummies(companies,drop_first=True) \n",
    "print(companies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2637, 1436)\n"
     ]
    }
   ],
   "source": [
    "features_words = pd.concat([features,companies], axis=1, sort=False)\n",
    "print(features_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_words.values, df.high_pay.values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8040201  0.73366834 0.71859296 0.7979798  0.78680203 0.80203046\n",
      " 0.81218274 0.75126904 0.74619289 0.8071066 ]\n",
      "0.7759844961360152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_scores = cross_val_score(BernoulliNB(), X_train, y_train, cv=10)\n",
    "print(nb_scores)\n",
    "print(np.mean(nb_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       high_p     low_p                 feature  high_diff\n",
      "134  0.484472  0.234483  information technology   0.249989\n",
      "149  0.484472  0.234483              technology   0.249989\n",
      "133  0.484472  0.234483             information   0.249989\n",
      "116  0.322981  0.140887            professional   0.182095\n",
      "117  0.260870  0.118227                  senior   0.142643\n",
      "111  0.211180  0.079803                 manager   0.131377\n",
      "110  0.154244  0.025616              management   0.128629\n",
      "55   0.221532  0.095567                 manager   0.125966\n",
      "80   0.199793  0.091626                  senior   0.108167\n",
      "256  0.126294  0.035468                  marina   0.090826\n",
      "       high_p     low_p            feature  high_diff\n",
      "122  0.003106  0.121182              admin  -0.118077\n",
      "123  0.003106  0.121182  admin secretarial  -0.118077\n",
      "146  0.003106  0.121182        secretarial  -0.118077\n",
      "115  0.045549  0.170443      non executive  -0.124895\n",
      "114  0.045549  0.170443                non  -0.124895\n",
      "14   0.013458  0.139901          assistant  -0.126444\n",
      "43   0.013458  0.150739          executive  -0.137281\n",
      "107  0.025880  0.187192             junior  -0.161312\n",
      "108  0.025880  0.187192   junior executive  -0.161312\n",
      "102  0.396480  0.735961          executive  -0.339480\n",
      "0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "feat_lp = nb.feature_log_prob_\n",
    "high_p = np.exp(feat_lp[1])\n",
    "low_p = np.exp(feat_lp[0])\n",
    "# Make a dataframe with the probabilities and features\n",
    "feat_probs = pd.DataFrame({'high_p':high_p, 'low_p':low_p, 'feature':features_words.columns.values})\n",
    "#  Create a column that is the difference between high probability of appearance and low\n",
    "feat_probs['high_diff'] = feat_probs.high_p - feat_probs.low_p\n",
    "\n",
    "# Look at the most likely words for high and low reviews\n",
    "feat_probs.sort_values('high_diff', ascending=False, inplace=True)  # most low, use ascending=True\n",
    "print(feat_probs.head(10))\n",
    "print(feat_probs.tail(10))\n",
    "# model on the test set\n",
    "print(nb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         predicted_high  predicted_low\n",
      "is_high             275             50\n",
      "is_low               72            263\n"
     ]
    }
   ],
   "source": [
    "y = df.high_pay.values\n",
    "X = features_words.values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.25)\n",
    "lr = LogisticRegression().fit(Xs, y)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predictions and pred prob.\n",
    "yhat = lr.predict(X_test)\n",
    "yhat_pp = lr.predict_proba(X_test)\n",
    "\n",
    "# confusion matrix metrics\n",
    "conmat = np.array(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['is_high', 'is_low'],\n",
    "                         columns=['predicted_high','predicted_low'])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.79      0.81       335\n",
      "         1.0       0.79      0.85      0.82       325\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       660\n",
      "   macro avg       0.82      0.82      0.82       660\n",
      "weighted avg       0.82      0.82      0.82       660\n",
      "\n",
      "recall 0.8461538461538461\n",
      "accuracy 0.8151515151515152\n",
      "precision 0.792507204610951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, yhat))\n",
    "# Support is simply the number of observations of the labeled class.\n",
    "# The marginal sum of rows in the confusion matrix or, in other words, the total number of observations belonging to a class, regardless of prediction.\n",
    "\n",
    "# recall\n",
    "from sklearn.metrics import recall_score\n",
    "print ('recall',recall_score(y_test, yhat))\n",
    "\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('accuracy',accuracy_score(y_test, yhat))\n",
    "\n",
    "# precision\n",
    "from sklearn.metrics import precision_score\n",
    "print ('precision',precision_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               logreg_coefs\n",
      "director                           1.868261\n",
      "manager                            1.215284\n",
      "manager                            1.058370\n",
      "head                               1.037224\n",
      "senior associate                   1.032047\n",
      "management                         0.950654\n",
      "google asia pacific pte. ltd.      0.921734\n",
      "scientist                          0.825769\n",
      "unilever asia private limited      0.825399\n",
      "analytics                          0.822351\n",
      "                                  logreg_coefs\n",
      "junior executive                     -0.599292\n",
      "engineering                          -0.664236\n",
      "temporary time                       -0.707778\n",
      "zalora south east asia pte. ltd.     -0.731701\n",
      "battery                              -0.740962\n",
      "specialist                           -0.772620\n",
      "marketing                            -0.827126\n",
      "assistant manager                    -0.894786\n",
      "associate                            -0.911423\n",
      "internship                           -1.230415\n"
     ]
    }
   ],
   "source": [
    "coeffs = pd.DataFrame(lr.coef_, columns=features_words.columns)\n",
    "coeffs_t = coeffs.transpose()\n",
    "coeffs_t.columns = ['logreg_coefs']\n",
    "coeffs_topbot = coeffs_t.sort_values('logreg_coefs', ascending=False)\n",
    "print(coeffs_topbot.head(10))\n",
    "print(coeffs_topbot.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 330 candidates, totalling 1650 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'max_depth': None, 'max_features': None, 'min_samples_split': 50}\n",
      "best_score: 0.8065761302059312\n"
     ]
    }
   ],
   "source": [
    "# try decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#  Set up and run the gridsearch on the data\n",
    "dtc_params = {\n",
    "    'max_depth':[None,1,2,3,4],\n",
    "    'max_features':[None,1,2,3,4,5],\n",
    "    'min_samples_split':[2,3,4,5,10,15,20,25,30,40,50]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# set the gridsearch\n",
    "dtc_gs = GridSearchCV(DecisionTreeClassifier(), \n",
    "                      dtc_params, \n",
    "                      cv=5, \n",
    "                      verbose=1, \n",
    "                      scoring='roc_auc', \n",
    "                      n_jobs=-1)\n",
    "\n",
    "dtc_gs.fit(features_words.values, df.high_pay.values)\n",
    "\n",
    "dtc_best = dtc_gs.best_estimator_\n",
    "print('best_params:' ,dtc_gs.best_params_)\n",
    "print('best_score:', dtc_gs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           feature  importance\n",
      "102                      executive    0.168870\n",
      "100                          entry    0.084616\n",
      "118               senior executive    0.067741\n",
      "133                    information    0.045160\n",
      "784  google asia pacific pte. ltd.    0.041521\n",
      "14                       assistant    0.026620\n",
      "43                       executive    0.025121\n",
      "44                          fellow    0.014566\n",
      "78                       scientist    0.013384\n",
      "80                          senior    0.010249\n",
      "                                              feature  importance\n",
      "549          business edge personnel services pte ltd         0.0\n",
      "539                       bradbury consulting pte ltd         0.0\n",
      "548                                    busads pte ltd         0.0\n",
      "547   bureau van dijk electronic publishing pte. ltd.         0.0\n",
      "545                        bruker singapore pte. ltd.         0.0\n",
      "543                           british high commission         0.0\n",
      "542               british council (singapore) limited         0.0\n",
      "541               brightline communications pte. ltd.         0.0\n",
      "540                bridgestone asia pacific pte. ltd.         0.0\n",
      "1435                                  zynit pte. ltd.         0.0\n"
     ]
    }
   ],
   "source": [
    "fi = pd.DataFrame({\n",
    "        'feature':features_words.columns,\n",
    "        'importance':dtc_best.feature_importances_\n",
    "    })\n",
    "\n",
    "fi.sort_values('importance', ascending=False, inplace=True)\n",
    "print(fi.head(10))\n",
    "print(fi.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine features\n",
    "\n",
    "- Best paying features: google asia pacific, \n",
    "\n",
    "- Worst paying features: temporary, contract, internship, flexi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1c) Look at columns 'job_description' and 'requirements'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), max_features=1500, binary=True, stop_words='english')\n",
    "jd_words = cv.fit_transform(df.job_description)\n",
    "jd_words = pd.DataFrame(jd_words.todense(), columns=cv.get_feature_names())\n",
    "X_train, X_test, y_train, y_test = train_test_split(jd_words.values, df.high_pay.values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70707071 0.75252525 0.67171717 0.69191919 0.67171717 0.71212121\n",
      " 0.72727273 0.73096447 0.74619289 0.75634518]\n",
      "0.71678459724145\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_scores = cross_val_score(BernoulliNB(), X_train, y_train, cv=10)\n",
    "print(nb_scores)\n",
    "print(np.mean(nb_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        high_p     low_p      feature  high_diff\n",
      "171   0.589286  0.276968     business   0.312318\n",
      "1368  0.359244  0.130224        teams   0.229020\n",
      "1274  0.365546  0.137026    solutions   0.228520\n",
      "1364  0.623950  0.410107         team   0.213843\n",
      "398   0.403361  0.201166       design   0.202195\n",
      "1377  0.307773  0.112731   technology   0.195042\n",
      "1193  0.350840  0.172983         role   0.177857\n",
      "168   0.256303  0.093294        build   0.163008\n",
      "410   0.401261  0.242954      develop   0.158306\n",
      "418   0.414916  0.257532  development   0.157384\n",
      "        high_p     low_p     feature  high_diff\n",
      "569   0.001050  0.103013      filing  -0.101962\n",
      "36    0.043067  0.147716      ad hoc  -0.104649\n",
      "35    0.047269  0.152575          ad  -0.105306\n",
      "654   0.043067  0.148688         hoc  -0.105621\n",
      "1152  0.169118  0.280855     reports  -0.111738\n",
      "110   0.102941  0.215743    assigned  -0.112802\n",
      "112   0.123950  0.241011      assist  -0.117061\n",
      "356   0.007353  0.136054  data entry  -0.128701\n",
      "511   0.013655  0.151603       entry  -0.137948\n",
      "451   0.070378  0.258503      duties  -0.188125\n",
      "0.7363636363636363\n"
     ]
    }
   ],
   "source": [
    "feat_lp = nb.feature_log_prob_\n",
    "high_p = np.exp(feat_lp[1])\n",
    "low_p = np.exp(feat_lp[0])\n",
    "# Make a dataframe with the probabilities and features\n",
    "feat_probs = pd.DataFrame({'high_p':high_p, 'low_p':low_p, 'feature':jd_words.columns.values})\n",
    "#  Create a column that is the difference between high probability of appearance and low\n",
    "feat_probs['high_diff'] = feat_probs.high_p - feat_probs.low_p\n",
    "\n",
    "# Look at the most likely words for high and low salary\n",
    "feat_probs.sort_values('high_diff', ascending=False, inplace=True)  # most low, use ascending=True\n",
    "print(feat_probs.head(10))\n",
    "print(feat_probs.tail(10))\n",
    "# model on the test set\n",
    "print(nb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         predicted_high  predicted_low\n",
      "is_high             250             84\n",
      "is_low               76            250\n"
     ]
    }
   ],
   "source": [
    "y = df.high_pay.values\n",
    "X = jd_words.values\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.25)\n",
    "lr = LogisticRegression().fit(Xs, y)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predictions and pred prob.\n",
    "yhat = lr.predict(X_test)\n",
    "yhat_pp = lr.predict_proba(X_test)\n",
    "\n",
    "# confusion matrix metrics\n",
    "conmat = np.array(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['is_high', 'is_low'],\n",
    "                         columns=['predicted_high','predicted_low'])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.77      0.76       326\n",
      "         1.0       0.77      0.75      0.76       334\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       660\n",
      "   macro avg       0.76      0.76      0.76       660\n",
      "weighted avg       0.76      0.76      0.76       660\n",
      "\n",
      "recall 0.7485029940119761\n",
      "accuracy 0.7575757575757576\n",
      "precision 0.7668711656441718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, yhat))\n",
    "# Support is simply the number of observations of the labeled class.\n",
    "# The marginal sum of rows in the confusion matrix or, in other words, the total number of observations belonging to a class, regardless of prediction.\n",
    "\n",
    "# recall\n",
    "from sklearn.metrics import recall_score\n",
    "print ('recall',recall_score(y_test, yhat))\n",
    "\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('accuracy',accuracy_score(y_test, yhat))\n",
    "\n",
    "# precision\n",
    "from sklearn.metrics import precision_score\n",
    "print ('precision',precision_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               logreg_coefs\n",
      "senior             1.003580\n",
      "lead               0.703744\n",
      "understanding      0.684230\n",
      "like               0.663862\n",
      "creating           0.652380\n",
      "variety            0.630907\n",
      "apac               0.630291\n",
      "skill              0.629081\n",
      "lifecycle          0.625729\n",
      "example            0.625506\n",
      "              logreg_coefs\n",
      "need             -0.502146\n",
      "stock            -0.502485\n",
      "terms            -0.508739\n",
      "analytical       -0.514360\n",
      "conversion       -0.516166\n",
      "house            -0.525220\n",
      "drives           -0.553535\n",
      "applications     -0.577807\n",
      "duties           -0.635769\n",
      "computer         -0.701632\n"
     ]
    }
   ],
   "source": [
    "coeffs = pd.DataFrame(lr.coef_, columns=jd_words.columns)\n",
    "coeffs_t = coeffs.transpose()\n",
    "coeffs_t.columns = ['logreg_coefs']\n",
    "coeffs_topbot = coeffs_t.sort_values('logreg_coefs', ascending=False)\n",
    "print(coeffs_topbot.head(10))\n",
    "print(coeffs_topbot.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 330 candidates, totalling 1650 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'max_depth': 4, 'max_features': None, 'min_samples_split': 2}\n",
      "best_score: 0.7194037736747323\n"
     ]
    }
   ],
   "source": [
    "# try decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#  Set up and run the gridsearch on the data\n",
    "dtc_params = {\n",
    "    'max_depth':[None,1,2,3,4],\n",
    "    'max_features':[None,1,2,3,4,5],\n",
    "    'min_samples_split':[2,3,4,5,10,15,20,25,30,40,50]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# set the gridsearch\n",
    "dtc_gs = GridSearchCV(DecisionTreeClassifier(), \n",
    "                      dtc_params, \n",
    "                      cv=5, \n",
    "                      verbose=1, \n",
    "                      scoring='roc_auc', \n",
    "                      n_jobs=-1)\n",
    "\n",
    "# use the gridearc C model to fit the data\n",
    "dtc_gs.fit(jd_words.values, df.high_pay.values)\n",
    "\n",
    "dtc_best = dtc_gs.best_estimator_\n",
    "print('best_params:' ,dtc_gs.best_params_)\n",
    "print('best_score:', dtc_gs.best_score_)\n",
    "\n",
    "# find \"feature importances\"\n",
    "\n",
    "# It ranges from 0 to 1, with 1 being the most important. feature importance is how much that particular variable was used to make decisions.\n",
    "# it also takes into account how much that feature contributed to splitting up the class or reducing the variance.\n",
    "#A feature with higher feature importance reduced the criterion (impurity) more than the other features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            feature  importance\n",
      "171        business    0.425636\n",
      "451          duties    0.147678\n",
      "1274      solutions    0.066504\n",
      "1377     technology    0.059714\n",
      "356      data entry    0.050953\n",
      "1133         region    0.046191\n",
      "398          design    0.038246\n",
      "732   international    0.035566\n",
      "1405          train    0.029286\n",
      "1429          units    0.026101\n",
      "                feature  importance\n",
      "505       ensure timely         0.0\n",
      "504         ensure data         0.0\n",
      "503   ensure compliance         0.0\n",
      "502              ensure         0.0\n",
      "501           enquiries         0.0\n",
      "500               enjoy         0.0\n",
      "499        enhancements         0.0\n",
      "498         enhancement         0.0\n",
      "497             enhance         0.0\n",
      "1499   years experience         0.0\n"
     ]
    }
   ],
   "source": [
    "fi = pd.DataFrame({\n",
    "        'feature':jd_words.columns,\n",
    "        'importance':dtc_best.feature_importances_\n",
    "    })\n",
    "\n",
    "fi.sort_values('importance', ascending=False, inplace=True)\n",
    "print(fi.head(10))\n",
    "print(fi.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), max_features=500, binary=True, stop_words='english')\n",
    "req_words = cv.fit_transform(df.requirements)\n",
    "\n",
    "req_words = pd.DataFrame(req_words.todense(), columns=cv.get_feature_names())\n",
    "X_train, X_test, y_train, y_test = train_test_split(req_words.values, df.high_pay.values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69191919 0.75252525 0.73737374 0.67676768 0.77272727 0.70707071\n",
      " 0.70707071 0.76142132 0.74111675 0.76142132]\n",
      "0.7309413936317489\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_scores = cross_val_score(BernoulliNB(), X_train, y_train, cv=10)\n",
    "print(nb_scores)\n",
    "print(np.mean(nb_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       high_p     low_p           feature  high_diff\n",
      "2    0.510395  0.299313           ability   0.211082\n",
      "467  0.325364  0.118744     understanding   0.206620\n",
      "111  0.312890  0.114818       development   0.198071\n",
      "435  0.511435  0.329735            strong   0.181699\n",
      "496  0.665281  0.486752             years   0.178529\n",
      "147  0.904366  0.736016        experience   0.168350\n",
      "497  0.319127  0.156035  years experience   0.163091\n",
      "248  0.433472  0.271835        management   0.161637\n",
      "89   0.424116  0.268891              data   0.155225\n",
      "46   0.367983  0.230618          business   0.137365\n",
      "       high_p     low_p     feature  high_diff\n",
      "5    0.082121  0.155054   able work  -0.072933\n",
      "48   0.085239  0.159961  candidates  -0.074722\n",
      "7    0.025988  0.105986  accounting  -0.079999\n",
      "176  0.340956  0.424926        good  -0.083970\n",
      "344  0.090437  0.176644  proficient  -0.086207\n",
      "274  0.073805  0.160942          ms  -0.087138\n",
      "139  0.115385  0.214917       excel  -0.099532\n",
      "264  0.076923  0.178606   microsoft  -0.101683\n",
      "287  0.086279  0.193327      office  -0.107048\n",
      "115  0.044699  0.264966     diploma  -0.220267\n",
      "0.7348484848484849\n"
     ]
    }
   ],
   "source": [
    "feat_lp = nb.feature_log_prob_\n",
    "high_p = np.exp(feat_lp[1])\n",
    "low_p = np.exp(feat_lp[0])\n",
    "# Make a dataframe with the probabilities and features\n",
    "feat_probs = pd.DataFrame({'high_p':high_p, 'low_p':low_p, 'feature':req_words.columns.values})\n",
    "#  Create a column that is the difference between high probability of appearance and low\n",
    "feat_probs['high_diff'] = feat_probs.high_p - feat_probs.low_p\n",
    "\n",
    "# Look at the most likely words for high and low salary\n",
    "feat_probs.sort_values('high_diff', ascending=False, inplace=True)  # most low, use ascending=True\n",
    "print(feat_probs.head(10))\n",
    "print(feat_probs.tail(10))\n",
    "# model on the test set\n",
    "print(nb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         predicted_high  predicted_low\n",
      "is_high             241            103\n",
      "is_low               96            220\n"
     ]
    }
   ],
   "source": [
    "y = df.high_pay.values\n",
    "X = req_words.values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.25)\n",
    "lr = LogisticRegression().fit(Xs, y)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predictions and pred prob.\n",
    "yhat = lr.predict(X_test)\n",
    "yhat_pp = lr.predict_proba(X_test)\n",
    "\n",
    "# confusion matrix metrics\n",
    "conmat = np.array(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['is_high', 'is_low'],\n",
    "                         columns=['predicted_high','predicted_low'])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.70      0.69       316\n",
      "         1.0       0.72      0.70      0.71       344\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       660\n",
      "   macro avg       0.70      0.70      0.70       660\n",
      "weighted avg       0.70      0.70      0.70       660\n",
      "\n",
      "recall 0.7005813953488372\n",
      "accuracy 0.6984848484848485\n",
      "precision 0.7151335311572701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, yhat))\n",
    "# Support is simply the number of observations of the labeled class.\n",
    "# The marginal sum of rows in the confusion matrix or, in other words, the total number of observations belonging to a class, regardless of prediction.\n",
    "\n",
    "# recall\n",
    "from sklearn.metrics import recall_score\n",
    "print ('recall',recall_score(y_test, yhat))\n",
    "\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('accuracy',accuracy_score(y_test, yhat))\n",
    "\n",
    "# precision\n",
    "from sklearn.metrics import precision_score\n",
    "print ('precision',precision_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      logreg_coefs\n",
      "candidates notified       0.856865\n",
      "shortlisted               0.821166\n",
      "practical                 0.750684\n",
      "player                    0.735283\n",
      "regret shortlisted        0.652758\n",
      "architecture              0.573697\n",
      "phd                       0.519550\n",
      "self starter              0.513826\n",
      "communication skills      0.501911\n",
      "ms office                 0.500870\n",
      "                        logreg_coefs\n",
      "regret                     -0.506502\n",
      "hands                      -0.557009\n",
      "computer                   -0.588008\n",
      "sg                         -0.630626\n",
      "shortlisted candidates     -0.640421\n",
      "candidates                 -0.653466\n",
      "diploma                    -0.687557\n",
      "ms                         -0.743880\n",
      "team player                -0.854804\n",
      "notified                   -0.923174\n"
     ]
    }
   ],
   "source": [
    "coeffs = pd.DataFrame(lr.coef_, columns=req_words.columns)\n",
    "coeffs_t = coeffs.transpose()\n",
    "coeffs_t.columns = ['logreg_coefs']\n",
    "coeffs_topbot = coeffs_t.sort_values('logreg_coefs', ascending=False)\n",
    "print(coeffs_topbot.head(10))\n",
    "print(coeffs_topbot.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 330 candidates, totalling 1650 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   43.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'max_depth': None, 'max_features': None, 'min_samples_split': 50}\n",
      "best_score: 0.7264848830657634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:   57.5s finished\n"
     ]
    }
   ],
   "source": [
    "# try decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#  Set up and run the gridsearch on the data\n",
    "dtc_params = {\n",
    "    'max_depth':[None,1,2,3,4],\n",
    "    'max_features':[None,1,2,3,4,5],\n",
    "    'min_samples_split':[2,3,4,5,10,15,20,25,30,40,50]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# set the gridsearch\n",
    "dtc_gs = GridSearchCV(DecisionTreeClassifier(), \n",
    "                      dtc_params, \n",
    "                      cv=5, \n",
    "                      verbose=1, \n",
    "                      scoring='roc_auc', \n",
    "                      n_jobs=-1)\n",
    "\n",
    "# use the gridearc C model to fit the data\n",
    "dtc_gs.fit(req_words.values, df.high_pay.values)\n",
    "\n",
    "dtc_best = dtc_gs.best_estimator_\n",
    "print('best_params:' ,dtc_gs.best_params_)\n",
    "print('best_score:', dtc_gs.best_score_)\n",
    "\n",
    "# find \"feature importances\"\n",
    "\n",
    "# It ranges from 0 to 1, with 1 being the most important. feature importance is how much that particular variable was used to make decisions.\n",
    "# it also takes into account how much that feature contributed to splitting up the class or reducing the variance.\n",
    "#A feature with higher feature importance reduced the criterion (impurity) more than the other features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           feature  importance\n",
      "115        diploma    0.148540\n",
      "147     experience    0.074869\n",
      "467  understanding    0.046063\n",
      "111    development    0.029808\n",
      "287         office    0.023988\n",
      "321      practical    0.019119\n",
      "42             big    0.018009\n",
      "1         10 years    0.017644\n",
      "200      including    0.016916\n",
      "348        project    0.014918\n",
      "                    feature  importance\n",
      "208              initiative         0.0\n",
      "207          infrastructure         0.0\n",
      "206  information technology         0.0\n",
      "205             information         0.0\n",
      "204               influence         0.0\n",
      "203                industry         0.0\n",
      "202           independently         0.0\n",
      "201             independent         0.0\n",
      "198             improvement         0.0\n",
      "499           years working         0.0\n"
     ]
    }
   ],
   "source": [
    "fi = pd.DataFrame({\n",
    "        'feature':req_words.columns,\n",
    "        'importance':dtc_best.feature_importances_\n",
    "    })\n",
    "\n",
    "fi.sort_values('importance', ascending=False, inplace=True)\n",
    "print(fi.head(10))\n",
    "print(fi.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Factors that distinguish job category. \n",
    "\n",
    "identify features in the data related to job postings that can distinguish job titles from each other\n",
    "\n",
    "2a) data scientists vs other data jobs?\n",
    "\n",
    "2b) distinguishing junior vs. senior positions\n",
    "\n",
    "2c) Do the requirements for titles vary significantly with industry ?\n",
    "\n",
    "Models used: BernoulliNB, Logistic regression, Decision tree Classifier, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>seniority</th>\n",
       "      <th>job_categories</th>\n",
       "      <th>job_description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>high_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>national university of singapore</td>\n",
       "      <td>senior / associate director, data governance /...</td>\n",
       "      <td>lower kent ridge road</td>\n",
       "      <td>permanent, full time</td>\n",
       "      <td>senior management</td>\n",
       "      <td>education and training, information technology</td>\n",
       "      <td>\\r\\r\\nthis leadership role will interact and e...</td>\n",
       "      <td>\\r\\r\\ndegree in information technology, comput...</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ntuc enterprise nexus co-operative limited</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>marina boulevard</td>\n",
       "      <td>full time</td>\n",
       "      <td>executive</td>\n",
       "      <td>information technology</td>\n",
       "      <td>\\r\\r\\nntuc enterprise is in the midst of its d...</td>\n",
       "      <td>\\r\\r\\n• masters in statistics, mathematics, co...</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     company  \\\n",
       "0           0            national university of singapore   \n",
       "1           1  ntuc enterprise nexus co-operative limited   \n",
       "\n",
       "                                           job_title                 location  \\\n",
       "0  senior / associate director, data governance /...   lower kent ridge road    \n",
       "1                                     data scientist        marina boulevard    \n",
       "\n",
       "        employment_type          seniority  \\\n",
       "0  permanent, full time  senior management   \n",
       "1             full time          executive   \n",
       "\n",
       "                                   job_categories  \\\n",
       "0  education and training, information technology   \n",
       "1                          information technology   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  \\r\\r\\nthis leadership role will interact and e...   \n",
       "1  \\r\\r\\nntuc enterprise is in the midst of its d...   \n",
       "\n",
       "                                        requirements  salary_low  salary_high  \\\n",
       "0  \\r\\r\\ndegree in information technology, comput...      7000.0       9000.0   \n",
       "1  \\r\\r\\n• masters in statistics, mathematics, co...      3500.0      10000.0   \n",
       "\n",
       "   salary_avg  high_pay  \n",
       "0      8000.0       1.0  \n",
       "1      6750.0       1.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a) data scientists vs other data jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scientist = df[df['job_title'].str.contains(\"scientist\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 13)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scientist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['job_title'].str.contains(\"scientist\"), 'data_sci'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.data_sci.replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>seniority</th>\n",
       "      <th>job_categories</th>\n",
       "      <th>job_description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>high_pay</th>\n",
       "      <th>data_sci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>national university of singapore</td>\n",
       "      <td>senior / associate director, data governance /...</td>\n",
       "      <td>lower kent ridge road</td>\n",
       "      <td>permanent, full time</td>\n",
       "      <td>senior management</td>\n",
       "      <td>education and training, information technology</td>\n",
       "      <td>\\r\\r\\nthis leadership role will interact and e...</td>\n",
       "      <td>\\r\\r\\ndegree in information technology, comput...</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ntuc enterprise nexus co-operative limited</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>marina boulevard</td>\n",
       "      <td>full time</td>\n",
       "      <td>executive</td>\n",
       "      <td>information technology</td>\n",
       "      <td>\\r\\r\\nntuc enterprise is in the midst of its d...</td>\n",
       "      <td>\\r\\r\\n• masters in statistics, mathematics, co...</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a*star research entities</td>\n",
       "      <td>scientist (data analytics) / i2r (a*star)</td>\n",
       "      <td>raffles place</td>\n",
       "      <td>contract, full time</td>\n",
       "      <td>professional</td>\n",
       "      <td>sciences / laboratory / r&amp;d</td>\n",
       "      <td>\\r\\r\\nabout the institute for infocomm researc...</td>\n",
       "      <td>\\r\\r\\nphd in computer science or other related...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>china aviation oil (singapore) corporation ltd</td>\n",
       "      <td>business data analyst</td>\n",
       "      <td>temasek boulevard</td>\n",
       "      <td>full time</td>\n",
       "      <td>senior executive</td>\n",
       "      <td>information technology</td>\n",
       "      <td>\\r\\r\\nresponsible for front desk business syst...</td>\n",
       "      <td>\\r\\r\\nbachelor degree or equivalent  \\r\\r\\n3-5...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>nityo infotech services pte. ltd.</td>\n",
       "      <td>big data security consultant</td>\n",
       "      <td>ubi crescent</td>\n",
       "      <td>contract</td>\n",
       "      <td>executive</td>\n",
       "      <td>information technology</td>\n",
       "      <td>\\r\\r\\nsolid technical knowledge in data discov...</td>\n",
       "      <td>\\r\\r\\nat least 4 years of experience in implem...</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         company  \\\n",
       "0           0                national university of singapore   \n",
       "1           1      ntuc enterprise nexus co-operative limited   \n",
       "2           2                        a*star research entities   \n",
       "3           4  china aviation oil (singapore) corporation ltd   \n",
       "4           5               nityo infotech services pte. ltd.   \n",
       "\n",
       "                                           job_title                 location  \\\n",
       "0  senior / associate director, data governance /...   lower kent ridge road    \n",
       "1                                     data scientist        marina boulevard    \n",
       "2          scientist (data analytics) / i2r (a*star)           raffles place    \n",
       "3                              business data analyst       temasek boulevard    \n",
       "4                       big data security consultant            ubi crescent    \n",
       "\n",
       "        employment_type          seniority  \\\n",
       "0  permanent, full time  senior management   \n",
       "1             full time          executive   \n",
       "2   contract, full time       professional   \n",
       "3             full time   senior executive   \n",
       "4              contract          executive   \n",
       "\n",
       "                                   job_categories  \\\n",
       "0  education and training, information technology   \n",
       "1                          information technology   \n",
       "2                     sciences / laboratory / r&d   \n",
       "3                          information technology   \n",
       "4                          information technology   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  \\r\\r\\nthis leadership role will interact and e...   \n",
       "1  \\r\\r\\nntuc enterprise is in the midst of its d...   \n",
       "2  \\r\\r\\nabout the institute for infocomm researc...   \n",
       "3  \\r\\r\\nresponsible for front desk business syst...   \n",
       "4  \\r\\r\\nsolid technical knowledge in data discov...   \n",
       "\n",
       "                                        requirements  salary_low  salary_high  \\\n",
       "0  \\r\\r\\ndegree in information technology, comput...      7000.0       9000.0   \n",
       "1  \\r\\r\\n• masters in statistics, mathematics, co...      3500.0      10000.0   \n",
       "2  \\r\\r\\nphd in computer science or other related...      4500.0       9000.0   \n",
       "3  \\r\\r\\nbachelor degree or equivalent  \\r\\r\\n3-5...      4000.0       8000.0   \n",
       "4  \\r\\r\\nat least 4 years of experience in implem...      6500.0       8500.0   \n",
       "\n",
       "   salary_avg  high_pay  data_sci  \n",
       "0      8000.0       1.0       0.0  \n",
       "1      6750.0       1.0       1.0  \n",
       "2      6750.0       1.0       1.0  \n",
       "3      6000.0       1.0       0.0  \n",
       "4      7500.0       1.0       0.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2637, 14)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2637, 2276)\n"
     ]
    }
   ],
   "source": [
    "# exclude job titles\n",
    "all_features = pd.concat([seniority_words,job_categories_words,location_words,employment_type_words,req_words,jd_words], axis=1, sort=False)\n",
    "print(all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_features.values, df.data_sci.values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9040404  0.94444444 0.94949495 0.89393939 0.93939394 0.94949495\n",
      " 0.93939394 0.90909091 0.95939086 0.91326531]\n",
      "0.9301949098359541\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_scores = cross_val_score(BernoulliNB(), X_train, y_train, cv=10)\n",
    "print(nb_scores)\n",
    "print(np.mean(nb_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        high_p     low_p           feature  high_diff\n",
      "519   0.666667  0.034878  machine learning   0.631789\n",
      "518   0.666667  0.038001           machine   0.628666\n",
      "508   0.700000  0.078605          learning   0.621395\n",
      "632   0.683333  0.089016            python   0.594317\n",
      "1996  0.583333  0.038522           science   0.544812\n",
      "708   0.516667  0.042166        statistics   0.474501\n",
      "365   0.800000  0.339927              data   0.460073\n",
      "1562  0.533333  0.083811          learning   0.449523\n",
      "1136  0.466667  0.017699      data science   0.448968\n",
      "1998  0.433333  0.009370         scientist   0.423963\n",
      "        high_p     low_p     feature  high_diff\n",
      "1933  0.066667  0.211869    required  -0.145202\n",
      "809   0.050000  0.198334  activities  -0.148334\n",
      "391   0.016667  0.166059     diploma  -0.149393\n",
      "758   0.316667  0.470068        work  -0.153401\n",
      "1609  0.250000  0.415409  management  -0.165409\n",
      "1827  0.083333  0.258719     process  -0.175386\n",
      "1606  0.100000  0.279542      manage  -0.179542\n",
      "524   0.166667  0.346694  management  -0.180028\n",
      "2121  0.250000  0.463300     support  -0.213300\n",
      "1278  0.100000  0.363352      ensure  -0.263352\n",
      "0.9196969696969697\n"
     ]
    }
   ],
   "source": [
    "feat_lp = nb.feature_log_prob_\n",
    "high_p = np.exp(feat_lp[1])\n",
    "low_p = np.exp(feat_lp[0])\n",
    "# Make a dataframe with the probabilities and features\n",
    "feat_probs = pd.DataFrame({'high_p':high_p, 'low_p':low_p, 'feature':all_features.columns.values})\n",
    "#  Create a column that is the difference between high probability of appearance and low\n",
    "feat_probs['high_diff'] = feat_probs.high_p - feat_probs.low_p\n",
    "\n",
    "# Look at the most likely words for data scientist and other jobs\n",
    "feat_probs.sort_values('high_diff', ascending=False, inplace=True)  # most low, use ascending=True\n",
    "print(feat_probs.head(10))\n",
    "print(feat_probs.tail(10))\n",
    "# model on the test set\n",
    "print(nb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         predicted_high  predicted_low\n",
      "is_high              10              5\n",
      "is_low               36            609\n"
     ]
    }
   ],
   "source": [
    "y = df.data_sci.values\n",
    "X = all_features.values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.25)\n",
    "lr = LogisticRegression().fit(Xs, y)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predictions and pred prob.\n",
    "yhat = lr.predict(X_test)\n",
    "yhat_pp = lr.predict_proba(X_test)\n",
    "\n",
    "# confusion matrix metrics\n",
    "conmat = np.array(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['is_high', 'is_low'],\n",
    "                         columns=['predicted_high','predicted_low'])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.97       645\n",
      "         1.0       0.22      0.67      0.33        15\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       660\n",
      "   macro avg       0.60      0.81      0.65       660\n",
      "weighted avg       0.97      0.94      0.95       660\n",
      "\n",
      "recall 0.6666666666666666\n",
      "accuracy 0.9378787878787879\n",
      "precision 0.21739130434782608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, yhat))\n",
    "# Support is simply the number of observations of the labeled class.\n",
    "# The marginal sum of rows in the confusion matrix or, in other words, the total number of observations belonging to a class, regardless of prediction.\n",
    "\n",
    "# recall\n",
    "from sklearn.metrics import recall_score\n",
    "print ('recall',recall_score(y_test, yhat))\n",
    "\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('accuracy',accuracy_score(y_test, yhat))\n",
    "\n",
    "# precision\n",
    "from sklearn.metrics import precision_score\n",
    "print ('precision',precision_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  logreg_coefs\n",
      "scientist             0.414746\n",
      "data scientist        0.366823\n",
      "spark                 0.204635\n",
      "scientific            0.174299\n",
      "enterprise            0.169497\n",
      "data science          0.166818\n",
      "analytic              0.166506\n",
      "anson                 0.160395\n",
      "methods               0.152620\n",
      "machine learning      0.151980\n",
      "                logreg_coefs\n",
      "license            -0.144409\n",
      "engineer           -0.150412\n",
      "automation         -0.154448\n",
      "contract           -0.158879\n",
      "platform           -0.163544\n",
      "workplace          -0.169008\n",
      "write              -0.169833\n",
      "reg                -0.172625\n",
      "implementation     -0.180173\n",
      "battery            -0.238940\n"
     ]
    }
   ],
   "source": [
    "coeffs = pd.DataFrame(lr.coef_, columns=all_features.columns)\n",
    "coeffs_t = coeffs.transpose()\n",
    "coeffs_t.columns = ['logreg_coefs']\n",
    "coeffs_topbot = coeffs_t.sort_values('logreg_coefs', ascending=False)\n",
    "print(coeffs_topbot.head(10))\n",
    "print(coeffs_topbot.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b) distinguishing junior vs. senior positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "senior_position = df[df['seniority'].str.contains(\"senior\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senior_position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['seniority'].str.contains(\"senior\"), 'senior_position'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.senior_position.replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>seniority</th>\n",
       "      <th>job_categories</th>\n",
       "      <th>job_description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>high_pay</th>\n",
       "      <th>data_sci</th>\n",
       "      <th>senior_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>national university of singapore</td>\n",
       "      <td>senior / associate director, data governance /...</td>\n",
       "      <td>lower kent ridge road</td>\n",
       "      <td>permanent, full time</td>\n",
       "      <td>senior management</td>\n",
       "      <td>education and training, information technology</td>\n",
       "      <td>\\r\\r\\nthis leadership role will interact and e...</td>\n",
       "      <td>\\r\\r\\ndegree in information technology, comput...</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ntuc enterprise nexus co-operative limited</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>marina boulevard</td>\n",
       "      <td>full time</td>\n",
       "      <td>executive</td>\n",
       "      <td>information technology</td>\n",
       "      <td>\\r\\r\\nntuc enterprise is in the midst of its d...</td>\n",
       "      <td>\\r\\r\\n• masters in statistics, mathematics, co...</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     company  \\\n",
       "0           0            national university of singapore   \n",
       "1           1  ntuc enterprise nexus co-operative limited   \n",
       "\n",
       "                                           job_title                 location  \\\n",
       "0  senior / associate director, data governance /...   lower kent ridge road    \n",
       "1                                     data scientist        marina boulevard    \n",
       "\n",
       "        employment_type          seniority  \\\n",
       "0  permanent, full time  senior management   \n",
       "1             full time          executive   \n",
       "\n",
       "                                   job_categories  \\\n",
       "0  education and training, information technology   \n",
       "1                          information technology   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  \\r\\r\\nthis leadership role will interact and e...   \n",
       "1  \\r\\r\\nntuc enterprise is in the midst of its d...   \n",
       "\n",
       "                                        requirements  salary_low  salary_high  \\\n",
       "0  \\r\\r\\ndegree in information technology, comput...      7000.0       9000.0   \n",
       "1  \\r\\r\\n• masters in statistics, mathematics, co...      3500.0      10000.0   \n",
       "\n",
       "   salary_avg  high_pay  data_sci  senior_position  \n",
       "0      8000.0       1.0       0.0              1.0  \n",
       "1      6750.0       1.0       1.0              0.0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2637, 2356)\n"
     ]
    }
   ],
   "source": [
    "# exclude seniority\n",
    "all_features = pd.concat([title_words,job_categories_words,location_words,employment_type_words,req_words,jd_words], axis=1, sort=False)\n",
    "print(all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_features.values, df.senior_position.values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70854271 0.71356784 0.7638191  0.75252525 0.66497462 0.7106599\n",
      " 0.69035533 0.7106599  0.67005076 0.69543147]\n",
      "0.708058688046189\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_scores = cross_val_score(BernoulliNB(), X_train, y_train, cv=10)\n",
    "print(nb_scores)\n",
    "print(np.mean(nb_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        high_p     low_p                 feature  high_diff\n",
      "80    0.333333  0.114826                  senior   0.218507\n",
      "1027  0.558081  0.407571                business   0.150510\n",
      "852   0.684343  0.552681                   years   0.131662\n",
      "791   0.507576  0.379180                  strong   0.128396\n",
      "1254  0.396465  0.270662                  design   0.125802\n",
      "1788  0.229798  0.114196             operational   0.115602\n",
      "114   0.454545  0.345110  information technology   0.109435\n",
      "113   0.454545  0.345110             information   0.109435\n",
      "129   0.454545  0.345110              technology   0.109435\n",
      "1909  0.303030  0.193691               processes   0.109339\n",
      "        high_p     low_p         feature  high_diff\n",
      "126   0.012626  0.069401     secretarial  -0.056774\n",
      "1691  0.123737  0.181703         manager  -0.057966\n",
      "902   0.022727  0.085804  administrative  -0.063077\n",
      "14    0.027778  0.094637       assistant  -0.066859\n",
      "731   0.118687  0.189905        required  -0.071218\n",
      "1212  0.010101  0.088328      data entry  -0.078227\n",
      "1842  0.166667  0.246057         perform  -0.079390\n",
      "471   0.090909  0.170978         diploma  -0.080069\n",
      "1307  0.111111  0.193060          duties  -0.081949\n",
      "1367  0.017677  0.100315           entry  -0.082639\n",
      "0.7363636363636363\n"
     ]
    }
   ],
   "source": [
    "feat_lp = nb.feature_log_prob_\n",
    "high_p = np.exp(feat_lp[1])\n",
    "low_p = np.exp(feat_lp[0])\n",
    "# Make a dataframe with the probabilities and features\n",
    "feat_probs = pd.DataFrame({'high_p':high_p, 'low_p':low_p, 'feature':all_features.columns.values})\n",
    "#  Create a column that is the difference between high probability of appearance and low\n",
    "feat_probs['high_diff'] = feat_probs.high_p - feat_probs.low_p\n",
    "\n",
    "# Look at the most likely words for senior and junior role\n",
    "feat_probs.sort_values('high_diff', ascending=False, inplace=True)  # most low, use ascending=True\n",
    "print(feat_probs.head(10))\n",
    "print(feat_probs.tail(10))\n",
    "\n",
    "# model on the test set\n",
    "print(nb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  use logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         predicted_high  predicted_low\n",
      "is_high              20              0\n",
      "is_low               38            602\n"
     ]
    }
   ],
   "source": [
    "y = df.data_sci.values\n",
    "X = all_features.values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.25)\n",
    "lr = LogisticRegression().fit(Xs, y)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predictions and pred prob.\n",
    "yhat = lr.predict(X_test)\n",
    "yhat_pp = lr.predict_proba(X_test)\n",
    "\n",
    "# confusion matrix metrics\n",
    "conmat = np.array(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['is_high', 'is_low'],\n",
    "                         columns=['predicted_high','predicted_low'])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97       640\n",
      "         1.0       0.34      1.00      0.51        20\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       660\n",
      "   macro avg       0.67      0.97      0.74       660\n",
      "weighted avg       0.98      0.94      0.96       660\n",
      "\n",
      "recall 1.0\n",
      "accuracy 0.9424242424242424\n",
      "precision 0.3448275862068966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, yhat))\n",
    "# Support is simply the number of observations of the labeled class.\n",
    "# The marginal sum of rows in the confusion matrix or, in other words, the total number of observations belonging to a class, regardless of prediction.\n",
    "\n",
    "# recall\n",
    "from sklearn.metrics import recall_score\n",
    "print ('recall',recall_score(y_test, yhat))\n",
    "\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('accuracy',accuracy_score(y_test, yhat))\n",
    "\n",
    "# precision\n",
    "from sklearn.metrics import precision_score\n",
    "print ('precision',precision_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                logreg_coefs\n",
      "scientist           1.031016\n",
      "data scientist      0.791236\n",
      "scientist           0.183748\n",
      "data                0.173265\n",
      "data scientist      0.158966\n",
      "vibrant             0.150510\n",
      "analytic            0.136657\n",
      "expertise           0.117478\n",
      "goal                0.113929\n",
      "budgets             0.113677\n",
      "               logreg_coefs\n",
      "developing        -0.082452\n",
      "extensive         -0.084526\n",
      "technology        -0.087750\n",
      "cloud             -0.089297\n",
      "engineer          -0.091662\n",
      "value             -0.093068\n",
      "real time         -0.099755\n",
      "university        -0.107744\n",
      "data analyst      -0.127364\n",
      "data engineer     -0.127733\n"
     ]
    }
   ],
   "source": [
    "coeffs = pd.DataFrame(lr.coef_, columns=all_features.columns)\n",
    "coeffs_t = coeffs.transpose()\n",
    "coeffs_t.columns = ['logreg_coefs']\n",
    "coeffs_topbot = coeffs_t.sort_values('logreg_coefs', ascending=False)\n",
    "print(coeffs_topbot.head(10))\n",
    "print(coeffs_topbot.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 330 candidates, totalling 1650 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'max_depth': None, 'max_features': None, 'min_samples_split': 25}\n",
      "best_score: 0.6668057015050338\n"
     ]
    }
   ],
   "source": [
    "# try decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#  Set up and run the gridsearch on the data\n",
    "dtc_params = {\n",
    "    'max_depth':[None,1,2,3,4],\n",
    "    'max_features':[None,1,2,3,4,5],\n",
    "    'min_samples_split':[2,3,4,5,10,15,20,25,30,40,50]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# set the gridsearch\n",
    "dtc_gs = GridSearchCV(DecisionTreeClassifier(), \n",
    "                      dtc_params, \n",
    "                      cv=5, \n",
    "                      verbose=1, \n",
    "                      scoring='roc_auc', \n",
    "                      n_jobs=-1)\n",
    "\n",
    "# use the gridearc C model to fit the data\n",
    "dtc_gs.fit(all_features.values, df.senior_position.values)\n",
    "\n",
    "dtc_best = dtc_gs.best_estimator_\n",
    "print('best_params:' ,dtc_gs.best_params_)\n",
    "print('best_score:', dtc_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                feature  importance\n",
      "1029  business function    0.092525\n",
      "80               senior    0.076606\n",
      "428            computer    0.016341\n",
      "197                 hoe    0.016036\n",
      "732        requirements    0.015082\n",
      "21             business    0.015013\n",
      "40             director    0.014895\n",
      "1345             engage    0.014500\n",
      "50                 head    0.014241\n",
      "1205               data    0.014043\n",
      "               feature  importance\n",
      "825                use         0.0\n",
      "824         university         0.0\n",
      "823      understanding         0.0\n",
      "822         understand         0.0\n",
      "821    troubleshooting         0.0\n",
      "820             trends         0.0\n",
      "819             travel         0.0\n",
      "818           training         0.0\n",
      "817       track record         0.0\n",
      "2355  years experience         0.0\n"
     ]
    }
   ],
   "source": [
    "fi = pd.DataFrame({\n",
    "        'feature':all_features.columns,\n",
    "        'importance':dtc_best.feature_importances_\n",
    "    })\n",
    "\n",
    "fi.sort_values('importance', ascending=False, inplace=True)\n",
    "print(fi.head(10))\n",
    "print(fi.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2c) Do the requirements for titles vary significantly with industry\n",
    "look at job_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "information technology                                                                                         780\n",
       "engineering                                                                                                    183\n",
       "accounting / auditing / taxation                                                                               134\n",
       "banking and finance                                                                                            124\n",
       "others                                                                                                         105\n",
       "sciences / laboratory / r&d                                                                                     99\n",
       "admin / secretarial                                                                                             90\n",
       "human resources                                                                                                 80\n",
       "marketing / public relations                                                                                    63\n",
       "logistics / supply chain                                                                                        56\n",
       "advertising / media                                                                                             52\n",
       "consulting                                                                                                      51\n",
       "sales / retail                                                                                                  50\n",
       "healthcare / pharmaceutical                                                                                     40\n",
       "education and training                                                                                          35\n",
       "banking and finance, information technology                                                                     32\n",
       "building and construction                                                                                       28\n",
       "general management                                                                                              24\n",
       "manufacturing                                                                                                   23\n",
       "repair and maintenance                                                                                          23\n",
       "engineering, information technology                                                                             22\n",
       "engineering, sciences / laboratory / r&d                                                                        19\n",
       "customer service                                                                                                18\n",
       "design                                                                                                          17\n",
       "consulting , information technology                                                                             17\n",
       "engineering, manufacturing                                                                                      16\n",
       "purchasing / merchandising                                                                                      15\n",
       "legal                                                                                                           14\n",
       "consulting , banking and finance, information technology                                                        12\n",
       "insurance                                                                                                       11\n",
       "                                                                                                              ... \n",
       "healthcare / pharmaceutical, logistics / supply chain                                                            1\n",
       "admin / secretarial, engineering, logistics / supply chain, manufacturing, purchasing / merchandising            1\n",
       "consulting , marketing / public relations , telecommunications                                                   1\n",
       "human resources , information technology                                                                         1\n",
       "admin / secretarial, building and construction                                                                   1\n",
       "building and construction, engineering, repair and maintenance                                                   1\n",
       "customer service, others                                                                                         1\n",
       "advertising / media , consulting , marketing / public relations , others, professional services                  1\n",
       "banking and finance, marketing / public relations                                                                1\n",
       "consulting , general management, professional services                                                           1\n",
       "customer service, engineering, others                                                                            1\n",
       "information technology, manufacturing, others                                                                    1\n",
       "admin / secretarial, insurance                                                                                   1\n",
       "customer service, human resources , medical / therapy services, sales / retail                                   1\n",
       "banking and finance, information technology, sales / retail                                                      1\n",
       "information technology, logistics / supply chain, manufacturing, purchasing / merchandising, sales / retail      1\n",
       "accounting / auditing / taxation, admin / secretarial, human resources                                           1\n",
       "banking and finance, security and investigation                                                                  1\n",
       "admin / secretarial, logistics / supply chain, others                                                            1\n",
       "advertising / media , information technology, sales / retail                                                     1\n",
       "architecture / interior design, building and construction                                                        1\n",
       "advertising / media , human resources                                                                            1\n",
       "accounting / auditing / taxation, admin / secretarial, consulting                                                1\n",
       "consulting , information technology, insurance                                                                   1\n",
       "customer service, healthcare / pharmaceutical                                                                    1\n",
       "architecture / interior design, building and construction, design                                                1\n",
       "admin / secretarial, customer service, human resources , general management                                      1\n",
       "architecture / interior design, marketing / public relations                                                     1\n",
       "building and construction, others                                                                                1\n",
       "engineering, marketing / public relations , sales / retail                                                       1\n",
       "Name: job_categories, Length: 261, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.job_categories.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information technology              780\n",
      "engineering                         183\n",
      "accounting / auditing / taxation    134\n",
      "banking and finance                 124\n",
      "Name: job_categories, dtype: int64\n",
      "(1221, 15)\n"
     ]
    }
   ],
   "source": [
    "# filter 'job_categories' to keep the top 4 job_categories\n",
    "counts = df['job_categories'].value_counts()\n",
    "mask =df['job_categories'].isin(counts[counts > 110].keys().values)\n",
    "df2=df.loc[mask, :]\n",
    "print(df2['job_categories'].value_counts())\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df['job_categories'].str.contains(\"information technology\"), 'four_categories'] = 0\n",
    "df2.loc[df['job_categories'].str.contains(\"engineering\"), 'four_categories'] = 1\n",
    "df2.loc[df['job_categories'].str.contains(\"accounting / auditing / taxation\"), 'four_categories'] = 2\n",
    "df2.loc[df['job_categories'].str.contains(\"banking and finance\"), 'four_categories'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    780\n",
       "1.0    183\n",
       "2.0    134\n",
       "3.0    124\n",
       "Name: four_categories, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.four_categories.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1221, 2346)\n"
     ]
    }
   ],
   "source": [
    "# exclude job_categories\n",
    "all_features = pd.concat([title_words,seniority_words,location_words,employment_type_words,req_words,jd_words], axis=1, sort=False)\n",
    "X=all_features.loc[mask, :]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, df2['four_categories'].values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77173913 0.81521739 0.73913043 0.72826087 0.84782609 0.75\n",
      " 0.77173913 0.82417582 0.76923077 0.79775281]\n",
      "0.7815072445873618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_scores = cross_val_score(BernoulliNB(), X_train, y_train, cv=10)\n",
    "print(nb_scores)\n",
    "print(np.mean(nb_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7826087  0.82608696 0.76086957 0.7826087  0.86956522 0.7826087\n",
      " 0.7826087  0.84615385 0.81318681 0.7752809 ]\n",
      "0.8021578079956194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "clf_scores = cross_val_score(MultinomialNB(), X_train, y_train, cv=10)\n",
    "print(clf_scores)\n",
    "print(np.mean(clf_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.81      0.85       191\n",
      "         1.0       0.68      0.68      0.68        56\n",
      "         2.0       0.64      0.72      0.68        25\n",
      "         3.0       0.54      0.79      0.64        34\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       306\n",
      "   macro avg       0.69      0.75      0.71       306\n",
      "weighted avg       0.80      0.78      0.78       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               feature  IT_engin\n",
      "1017          business  0.002379\n",
      "781             strong  0.001560\n",
      "435               data  0.001520\n",
      "392           business  0.001446\n",
      "771                sql  0.001393\n",
      "594         management  0.001365\n",
      "419   computer science  0.001275\n",
      "823                web  0.001250\n",
      "457        development  0.001185\n",
      "797       technologies  0.001173\n",
      "             feature  IT_engin\n",
      "1338        engineer -0.001322\n",
      "2134  specifications -0.001406\n",
      "461          diploma -0.001521\n",
      "1292        drawings -0.001638\n",
      "604       mechanical -0.001638\n",
      "474       electrical -0.001713\n",
      "1361       equipment -0.001818\n",
      "1339     engineering -0.002563\n",
      "477      engineering -0.003212\n",
      "41          engineer -0.003237\n",
      "               feature    IT_acc\n",
      "1244            design  0.003033\n",
      "457        development  0.002489\n",
      "1264       development  0.002333\n",
      "419   computer science  0.002242\n",
      "2217         technical  0.002208\n",
      "735            science  0.002138\n",
      "771                sql  0.002083\n",
      "418           computer  0.002083\n",
      "795          technical  0.002044\n",
      "2223        technology  0.001912\n",
      "         feature    IT_acc\n",
      "881           ad -0.003465\n",
      "1500         hoc -0.003490\n",
      "882       ad hoc -0.003490\n",
      "1297      duties -0.003545\n",
      "1417     finance -0.003733\n",
      "1998     reports -0.003939\n",
      "1418   financial -0.004250\n",
      "862   accounting -0.005227\n",
      "863     accounts -0.005230\n",
      "353   accounting -0.005965\n",
      "               feature   IT_bank\n",
      "1244            design  0.002113\n",
      "2217         technical  0.001946\n",
      "418           computer  0.001896\n",
      "419   computer science  0.001844\n",
      "2116          software  0.001768\n",
      "735            science  0.001723\n",
      "1195              data  0.001668\n",
      "761           software  0.001632\n",
      "457        development  0.001615\n",
      "1264       development  0.001580\n",
      "         feature   IT_bank\n",
      "512    financial -0.001280\n",
      "1985  regulatory -0.001297\n",
      "382      banking -0.001301\n",
      "2034        risk -0.001365\n",
      "511      finance -0.001477\n",
      "1459      global -0.001521\n",
      "1629     leading -0.001525\n",
      "1693     markets -0.001640\n",
      "1418   financial -0.001695\n",
      "1584  investment -0.001812\n"
     ]
    }
   ],
   "source": [
    "feat_lp = clf.feature_log_prob_\n",
    "IT_p = np.exp(feat_lp[0])\n",
    "engineering_p = np.exp(feat_lp[1])\n",
    "accounting_p = np.exp(feat_lp[2])\n",
    "banking_p = np.exp(feat_lp[3])\n",
    "\n",
    "# Make a dataframe with the probabilities and features\n",
    "feat_probs = pd.DataFrame({'IT_p':IT_p, 'engineering_p':engineering_p, 'accounting_p':accounting_p,'banking_p':banking_p,'feature':all_features.columns.values})\n",
    "#  Create a column that is the difference between high probability of IT and other job\n",
    "feat_probs['IT_engin'] = feat_probs.IT_p - feat_probs.engineering_p\n",
    "feat_probs['IT_acc'] = feat_probs.IT_p - feat_probs.accounting_p\n",
    "feat_probs['IT_bank'] = feat_probs.IT_p - feat_probs.banking_p\n",
    "\n",
    "# Look at the most likely words for IT and other job\n",
    "feat_probs.sort_values('IT_engin', ascending=False, inplace=True)  \n",
    "print(feat_probs.loc[:,['feature','IT_engin']].head(10))\n",
    "print(feat_probs.loc[:,['feature','IT_engin']].tail(10))\n",
    "feat_probs.sort_values('IT_acc', ascending=False, inplace=True)\n",
    "print(feat_probs.loc[:,['feature','IT_acc']].head(10))\n",
    "print(feat_probs.loc[:,['feature','IT_acc']].tail(10))\n",
    "feat_probs.sort_values('IT_bank', ascending=False, inplace=True)  \n",
    "print(feat_probs.loc[:,['feature','IT_bank']].head(10))\n",
    "print(feat_probs.loc[:,['feature','IT_bank']].tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  use logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          predicted_IT  predicted_engin  predicted_acc  predicted_bank\n",
      "is_IT              148               24              6              25\n",
      "is_engin             4               32              3               0\n",
      "is_acc               0                1             22               5\n",
      "is_bank              5                1              1              29\n"
     ]
    }
   ],
   "source": [
    "y = df2.four_categories.values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.25)\n",
    "lr = LogisticRegression().fit(Xs, y)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predictions and pred prob.\n",
    "yhat = lr.predict(X_test)\n",
    "yhat_pp = lr.predict_proba(X_test)\n",
    "\n",
    "# confusion matrix metrics\n",
    "conmat = np.array(confusion_matrix(y_test, yhat, labels=[0,1,2,3]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['is_IT', 'is_engin','is_acc','is_bank'],\n",
    "                         columns=['predicted_IT', 'predicted_engin','predicted_acc','predicted_bank'])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.73      0.82       203\n",
      "         1.0       0.55      0.82      0.66        39\n",
      "         2.0       0.69      0.79      0.73        28\n",
      "         3.0       0.49      0.81      0.61        36\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       306\n",
      "   macro avg       0.67      0.79      0.71       306\n",
      "weighted avg       0.82      0.75      0.77       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, yhat))\n",
    "# Support is simply the number of observations of the labeled class.\n",
    "# The marginal sum of rows in the confusion matrix or, in other words, the total number of observations belonging to a class, regardless of prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = pd.DataFrame({'IT':lr.coef_[0]})\n",
    "df_log['Engin'] = pd.DataFrame({'Engin':lr.coef_[1]})\n",
    "df_log['Acc'] = pd.DataFrame({'Acc':lr.coef_[2]})\n",
    "df_log['Bank'] = pd.DataFrame({'Bank':lr.coef_[3]})\n",
    "df_log['Features'] = pd.DataFrame({'Features':X.columns})\n",
    "# look at features that are important for the 4 job categories below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IT</th>\n",
       "      <th>Engin</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Bank</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.443393</td>\n",
       "      <td>-0.482776</td>\n",
       "      <td>0.030415</td>\n",
       "      <td>0.128679</td>\n",
       "      <td>permanent time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0.345924</td>\n",
       "      <td>-0.305553</td>\n",
       "      <td>0.148922</td>\n",
       "      <td>-0.140378</td>\n",
       "      <td>permanent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>0.255096</td>\n",
       "      <td>-0.143817</td>\n",
       "      <td>-0.005332</td>\n",
       "      <td>-0.078297</td>\n",
       "      <td>security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>0.234966</td>\n",
       "      <td>-0.154956</td>\n",
       "      <td>-0.065215</td>\n",
       "      <td>-0.123942</td>\n",
       "      <td>program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.216684</td>\n",
       "      <td>-0.100098</td>\n",
       "      <td>0.009005</td>\n",
       "      <td>-0.057110</td>\n",
       "      <td>contract time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0.212528</td>\n",
       "      <td>-0.152652</td>\n",
       "      <td>0.030893</td>\n",
       "      <td>-0.160489</td>\n",
       "      <td>various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.212034</td>\n",
       "      <td>-0.147859</td>\n",
       "      <td>-0.040095</td>\n",
       "      <td>0.113079</td>\n",
       "      <td>contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.211756</td>\n",
       "      <td>-0.168358</td>\n",
       "      <td>-0.010947</td>\n",
       "      <td>-0.049815</td>\n",
       "      <td>consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>0.208301</td>\n",
       "      <td>-0.111962</td>\n",
       "      <td>-0.081939</td>\n",
       "      <td>-0.042447</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.197454</td>\n",
       "      <td>-0.159049</td>\n",
       "      <td>-0.032161</td>\n",
       "      <td>-0.060207</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>0.189586</td>\n",
       "      <td>-0.118364</td>\n",
       "      <td>0.017345</td>\n",
       "      <td>-0.021385</td>\n",
       "      <td>access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.183953</td>\n",
       "      <td>-0.053336</td>\n",
       "      <td>-0.046926</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>0.181148</td>\n",
       "      <td>-0.147181</td>\n",
       "      <td>0.064750</td>\n",
       "      <td>-0.068724</td>\n",
       "      <td>build</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.178245</td>\n",
       "      <td>-0.135026</td>\n",
       "      <td>-0.125948</td>\n",
       "      <td>-0.022501</td>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.177761</td>\n",
       "      <td>-0.104074</td>\n",
       "      <td>0.037730</td>\n",
       "      <td>-0.036182</td>\n",
       "      <td>application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.174559</td>\n",
       "      <td>-0.072355</td>\n",
       "      <td>-0.059324</td>\n",
       "      <td>-0.055419</td>\n",
       "      <td>domain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.174120</td>\n",
       "      <td>-0.129333</td>\n",
       "      <td>-0.067655</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>0.172699</td>\n",
       "      <td>-0.149124</td>\n",
       "      <td>-0.173682</td>\n",
       "      <td>-0.093140</td>\n",
       "      <td>monitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.171252</td>\n",
       "      <td>-0.106411</td>\n",
       "      <td>-0.005983</td>\n",
       "      <td>-0.122497</td>\n",
       "      <td>work experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.170498</td>\n",
       "      <td>-0.115243</td>\n",
       "      <td>-0.039870</td>\n",
       "      <td>-0.069722</td>\n",
       "      <td>database</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            IT     Engin       Acc      Bank          Features\n",
       "332   0.443393 -0.482776  0.030415  0.128679    permanent time\n",
       "329   0.345924 -0.305553  0.148922 -0.140378         permanent\n",
       "2077  0.255096 -0.143817 -0.005332 -0.078297          security\n",
       "1916  0.234966 -0.154956 -0.065215 -0.123942           program\n",
       "323   0.216684 -0.100098  0.009005 -0.057110     contract time\n",
       "819   0.212528 -0.152652  0.030893 -0.160489           various\n",
       "320   0.212034 -0.147859 -0.040095  0.113079          contract\n",
       "26    0.211756 -0.168358 -0.010947 -0.049815        consultant\n",
       "1463  0.208301 -0.111962 -0.081939 -0.042447              good\n",
       "59    0.197454 -0.159049 -0.032161 -0.060207           network\n",
       "855   0.189586 -0.118364  0.017345 -0.021385            access\n",
       "433   0.183953 -0.053336 -0.046926 -0.000253  customer service\n",
       "1014  0.181148 -0.147181  0.064750 -0.068724             build\n",
       "9     0.178245 -0.135026 -0.125948 -0.022501           analyst\n",
       "368   0.177761 -0.104074  0.037730 -0.036182       application\n",
       "466   0.174559 -0.072355 -0.059324 -0.055419            domain\n",
       "744   0.174120 -0.129333 -0.067655  0.007494            server\n",
       "1733  0.172699 -0.149124 -0.173682 -0.093140           monitor\n",
       "829   0.171252 -0.106411 -0.005983 -0.122497   work experience\n",
       "437   0.170498 -0.115243 -0.039870 -0.069722          database"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log.sort_values('IT',ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IT</th>\n",
       "      <th>Engin</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Bank</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>-0.219835</td>\n",
       "      <td>0.408194</td>\n",
       "      <td>-0.098317</td>\n",
       "      <td>-0.007390</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.283179</td>\n",
       "      <td>0.406128</td>\n",
       "      <td>-0.075604</td>\n",
       "      <td>-0.069100</td>\n",
       "      <td>engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>-0.160297</td>\n",
       "      <td>0.392788</td>\n",
       "      <td>-0.137205</td>\n",
       "      <td>-0.045848</td>\n",
       "      <td>mechanical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>-0.181136</td>\n",
       "      <td>0.340608</td>\n",
       "      <td>-0.090579</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>-0.167880</td>\n",
       "      <td>0.327395</td>\n",
       "      <td>-0.083715</td>\n",
       "      <td>-0.056532</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>-0.135610</td>\n",
       "      <td>0.318694</td>\n",
       "      <td>-0.028294</td>\n",
       "      <td>-0.022619</td>\n",
       "      <td>drawings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>-0.160364</td>\n",
       "      <td>0.305954</td>\n",
       "      <td>-0.125306</td>\n",
       "      <td>-0.070370</td>\n",
       "      <td>electrical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>-0.181636</td>\n",
       "      <td>0.280145</td>\n",
       "      <td>-0.025154</td>\n",
       "      <td>0.007266</td>\n",
       "      <td>manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>-0.186642</td>\n",
       "      <td>0.273703</td>\n",
       "      <td>0.036365</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>-0.115977</td>\n",
       "      <td>0.246596</td>\n",
       "      <td>-0.067375</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>-0.103282</td>\n",
       "      <td>0.242030</td>\n",
       "      <td>-0.080731</td>\n",
       "      <td>0.014350</td>\n",
       "      <td>plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.119475</td>\n",
       "      <td>0.241982</td>\n",
       "      <td>-0.076271</td>\n",
       "      <td>-0.006401</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>-0.124276</td>\n",
       "      <td>0.238594</td>\n",
       "      <td>0.099268</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>inspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>-0.128555</td>\n",
       "      <td>0.231222</td>\n",
       "      <td>-0.020459</td>\n",
       "      <td>-0.057032</td>\n",
       "      <td>engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>-0.142926</td>\n",
       "      <td>0.230538</td>\n",
       "      <td>0.038609</td>\n",
       "      <td>0.075896</td>\n",
       "      <td>routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>-0.055314</td>\n",
       "      <td>0.216400</td>\n",
       "      <td>0.062385</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-0.109889</td>\n",
       "      <td>0.213028</td>\n",
       "      <td>-0.008855</td>\n",
       "      <td>-0.008546</td>\n",
       "      <td>park street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>-0.109889</td>\n",
       "      <td>0.213028</td>\n",
       "      <td>-0.008855</td>\n",
       "      <td>-0.008546</td>\n",
       "      <td>woodlands ind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-0.109889</td>\n",
       "      <td>0.213028</td>\n",
       "      <td>-0.008855</td>\n",
       "      <td>-0.008546</td>\n",
       "      <td>ind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.109889</td>\n",
       "      <td>0.213028</td>\n",
       "      <td>-0.008855</td>\n",
       "      <td>-0.008546</td>\n",
       "      <td>ind park</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            IT     Engin       Acc      Bank       Features\n",
       "477  -0.219835  0.408194 -0.098317 -0.007390    engineering\n",
       "41   -0.283179  0.406128 -0.075604 -0.069100       engineer\n",
       "604  -0.160297  0.392788 -0.137205 -0.045848     mechanical\n",
       "1339 -0.181136  0.340608 -0.090579  0.005896    engineering\n",
       "2049 -0.167880  0.327395 -0.083715 -0.056532         safety\n",
       "1292 -0.135610  0.318694 -0.028294 -0.022619       drawings\n",
       "474  -0.160364  0.305954 -0.125306 -0.070370     electrical\n",
       "1687 -0.181636  0.280145 -0.025154  0.007266  manufacturing\n",
       "1134 -0.186642  0.273703  0.036365  0.027232   construction\n",
       "1361 -0.115977  0.246596 -0.067375  0.008166      equipment\n",
       "1848 -0.103282  0.242030 -0.080731  0.014350           plan\n",
       "42   -0.119475  0.241982 -0.076271 -0.006401    engineering\n",
       "1556 -0.124276  0.238594  0.099268  0.018085     inspection\n",
       "1341 -0.128555  0.231222 -0.020459 -0.057032      engineers\n",
       "2044 -0.142926  0.230538  0.038609  0.075896        routine\n",
       "1403 -0.055314  0.216400  0.062385  0.008996     facilities\n",
       "248  -0.109889  0.213028 -0.008855 -0.008546    park street\n",
       "317  -0.109889  0.213028 -0.008855 -0.008546  woodlands ind\n",
       "189  -0.109889  0.213028 -0.008855 -0.008546            ind\n",
       "190  -0.109889  0.213028 -0.008855 -0.008546       ind park"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log.sort_values('Engin',ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IT</th>\n",
       "      <th>Engin</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Bank</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.260064</td>\n",
       "      <td>-0.075387</td>\n",
       "      <td>0.463401</td>\n",
       "      <td>-0.116321</td>\n",
       "      <td>accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.103687</td>\n",
       "      <td>-0.030477</td>\n",
       "      <td>0.445390</td>\n",
       "      <td>-0.230845</td>\n",
       "      <td>accounts assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.002899</td>\n",
       "      <td>-0.044628</td>\n",
       "      <td>0.411649</td>\n",
       "      <td>-0.426200</td>\n",
       "      <td>central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>-0.101340</td>\n",
       "      <td>-0.006576</td>\n",
       "      <td>0.363237</td>\n",
       "      <td>-0.040005</td>\n",
       "      <td>laws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>-0.185559</td>\n",
       "      <td>-0.066813</td>\n",
       "      <td>0.310465</td>\n",
       "      <td>-0.056231</td>\n",
       "      <td>accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-0.118506</td>\n",
       "      <td>0.106562</td>\n",
       "      <td>0.303210</td>\n",
       "      <td>-0.313866</td>\n",
       "      <td>boon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.123473</td>\n",
       "      <td>-0.042845</td>\n",
       "      <td>0.288632</td>\n",
       "      <td>-0.189325</td>\n",
       "      <td>assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>-0.053144</td>\n",
       "      <td>-0.019720</td>\n",
       "      <td>0.281871</td>\n",
       "      <td>-0.018145</td>\n",
       "      <td>statutory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.110623</td>\n",
       "      <td>-0.010613</td>\n",
       "      <td>0.279675</td>\n",
       "      <td>0.014973</td>\n",
       "      <td>account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>-0.124422</td>\n",
       "      <td>-0.021453</td>\n",
       "      <td>0.275219</td>\n",
       "      <td>0.027056</td>\n",
       "      <td>month end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>-0.112193</td>\n",
       "      <td>-0.050067</td>\n",
       "      <td>0.268275</td>\n",
       "      <td>-0.074416</td>\n",
       "      <td>invoices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>-0.113598</td>\n",
       "      <td>-0.109961</td>\n",
       "      <td>0.262743</td>\n",
       "      <td>-0.151216</td>\n",
       "      <td>accounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>-0.051721</td>\n",
       "      <td>-0.016240</td>\n",
       "      <td>0.262659</td>\n",
       "      <td>-0.079520</td>\n",
       "      <td>timely accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>-0.096059</td>\n",
       "      <td>0.016351</td>\n",
       "      <td>0.262518</td>\n",
       "      <td>0.057246</td>\n",
       "      <td>reconciliation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>-0.166231</td>\n",
       "      <td>-0.074544</td>\n",
       "      <td>0.258557</td>\n",
       "      <td>0.056277</td>\n",
       "      <td>data entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0.010595</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.241824</td>\n",
       "      <td>0.019236</td>\n",
       "      <td>achieving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>-0.185662</td>\n",
       "      <td>-0.050394</td>\n",
       "      <td>0.236658</td>\n",
       "      <td>-0.027692</td>\n",
       "      <td>tax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>-0.135715</td>\n",
       "      <td>-0.050969</td>\n",
       "      <td>0.232898</td>\n",
       "      <td>0.063625</td>\n",
       "      <td>entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>-0.043608</td>\n",
       "      <td>0.175665</td>\n",
       "      <td>0.232663</td>\n",
       "      <td>0.237345</td>\n",
       "      <td>audience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.104977</td>\n",
       "      <td>-0.067669</td>\n",
       "      <td>0.218682</td>\n",
       "      <td>-0.031527</td>\n",
       "      <td>accounts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            IT     Engin       Acc      Bank            Features\n",
       "353  -0.260064 -0.075387  0.463401 -0.116321          accounting\n",
       "2    -0.103687 -0.030477  0.445390 -0.230845  accounts assistant\n",
       "149  -0.002899 -0.044628  0.411649 -0.426200             central\n",
       "1623 -0.101340 -0.006576  0.363237 -0.040005                laws\n",
       "862  -0.185559 -0.066813  0.310465 -0.056231          accounting\n",
       "134  -0.118506  0.106562  0.303210 -0.313866                boon\n",
       "14   -0.123473 -0.042845  0.288632 -0.189325           assistant\n",
       "2154 -0.053144 -0.019720  0.281871 -0.018145           statutory\n",
       "0    -0.110623 -0.010613  0.279675  0.014973             account\n",
       "1736 -0.124422 -0.021453  0.275219  0.027056           month end\n",
       "1586 -0.112193 -0.050067  0.268275 -0.074416            invoices\n",
       "863  -0.113598 -0.109961  0.262743 -0.151216            accounts\n",
       "2242 -0.051721 -0.016240  0.262659 -0.079520     timely accurate\n",
       "1970 -0.096059  0.016351  0.262518  0.057246      reconciliation\n",
       "1202 -0.166231 -0.074544  0.258557  0.056277          data entry\n",
       "870   0.010595  0.001511  0.241824  0.019236           achieving\n",
       "2208 -0.185662 -0.050394  0.236658 -0.027692                 tax\n",
       "1357 -0.135715 -0.050969  0.232898  0.063625               entry\n",
       "969  -0.043608  0.175665  0.232663  0.237345            audience\n",
       "1    -0.104977 -0.067669  0.218682 -0.031527            accounts"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log.sort_values('Acc',ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IT</th>\n",
       "      <th>Engin</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Bank</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>-0.177741</td>\n",
       "      <td>-0.060824</td>\n",
       "      <td>-0.148046</td>\n",
       "      <td>0.426246</td>\n",
       "      <td>investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.163671</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.170618</td>\n",
       "      <td>0.285032</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>-0.200933</td>\n",
       "      <td>0.083871</td>\n",
       "      <td>0.014980</td>\n",
       "      <td>0.283410</td>\n",
       "      <td>markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>-0.154924</td>\n",
       "      <td>-0.032635</td>\n",
       "      <td>-0.143968</td>\n",
       "      <td>0.277425</td>\n",
       "      <td>regulatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>-0.106049</td>\n",
       "      <td>-0.091034</td>\n",
       "      <td>-0.135334</td>\n",
       "      <td>0.268336</td>\n",
       "      <td>banking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>-0.086346</td>\n",
       "      <td>-0.007496</td>\n",
       "      <td>0.041818</td>\n",
       "      <td>0.266904</td>\n",
       "      <td>trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>-0.041810</td>\n",
       "      <td>-0.076114</td>\n",
       "      <td>-0.080372</td>\n",
       "      <td>0.242304</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.133509</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.038675</td>\n",
       "      <td>0.242253</td>\n",
       "      <td>banking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>-0.077757</td>\n",
       "      <td>0.065640</td>\n",
       "      <td>0.012734</td>\n",
       "      <td>0.241314</td>\n",
       "      <td>opportunities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>-0.043608</td>\n",
       "      <td>0.175665</td>\n",
       "      <td>0.232663</td>\n",
       "      <td>0.237345</td>\n",
       "      <td>audience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.123651</td>\n",
       "      <td>-0.013107</td>\n",
       "      <td>-0.086184</td>\n",
       "      <td>0.232577</td>\n",
       "      <td>account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-0.257632</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>0.087043</td>\n",
       "      <td>0.230598</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>-0.086029</td>\n",
       "      <td>-0.025652</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.214686</td>\n",
       "      <td>firm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>-0.059353</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>-0.016161</td>\n",
       "      <td>0.211841</td>\n",
       "      <td>marina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.023090</td>\n",
       "      <td>-0.038950</td>\n",
       "      <td>-0.192859</td>\n",
       "      <td>0.208770</td>\n",
       "      <td>accounts executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>-0.127480</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>0.207564</td>\n",
       "      <td>leading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>-0.055741</td>\n",
       "      <td>-0.032754</td>\n",
       "      <td>-0.026844</td>\n",
       "      <td>0.206067</td>\n",
       "      <td>credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.063998</td>\n",
       "      <td>-0.007398</td>\n",
       "      <td>-0.039014</td>\n",
       "      <td>0.202652</td>\n",
       "      <td>customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>-0.076730</td>\n",
       "      <td>0.053131</td>\n",
       "      <td>0.024589</td>\n",
       "      <td>0.201414</td>\n",
       "      <td>automate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>-0.089604</td>\n",
       "      <td>0.082244</td>\n",
       "      <td>-0.030052</td>\n",
       "      <td>0.198730</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            IT     Engin       Acc      Bank            Features\n",
       "1584 -0.177741 -0.060824 -0.148046  0.426246          investment\n",
       "47   -0.163671 -0.046875 -0.170618  0.285032               group\n",
       "1693 -0.200933  0.083871  0.014980  0.283410             markets\n",
       "1985 -0.154924 -0.032635 -0.143968  0.277425          regulatory\n",
       "382  -0.106049 -0.091034 -0.135334  0.268336             banking\n",
       "2250 -0.086346 -0.007496  0.041818  0.266904             trading\n",
       "1863 -0.041810 -0.076114 -0.080372  0.242304            positive\n",
       "18   -0.133509  0.002822  0.038675  0.242253             banking\n",
       "638  -0.077757  0.065640  0.012734  0.241314       opportunities\n",
       "969  -0.043608  0.175665  0.232663  0.237345            audience\n",
       "352  -0.123651 -0.013107 -0.086184  0.232577             account\n",
       "512  -0.257632  0.008520  0.087043  0.230598           financial\n",
       "1422 -0.086029 -0.025652  0.004697  0.214686                firm\n",
       "226  -0.059353 -0.002032 -0.016161  0.211841              marina\n",
       "3    -0.023090 -0.038950 -0.192859  0.208770  accounts executive\n",
       "1629 -0.127480  0.061587  0.073638  0.207564             leading\n",
       "1175 -0.055741 -0.032754 -0.026844  0.206067              credit\n",
       "30   -0.063998 -0.007398 -0.039014  0.202652    customer service\n",
       "973  -0.076730  0.053131  0.024589  0.201414            automate\n",
       "846  -0.089604  0.082244 -0.030052  0.198730                 000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log.sort_values('Bank',ascending = False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
